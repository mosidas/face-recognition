#!/usr/bin/env python3
"""
ONNX Model Analyzer Tool
ONNXãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ä»•æ§˜ã‚’åˆ†æã™ã‚‹ãƒ„ãƒ¼ãƒ«
"""

import onnx
import onnxruntime as ort
import numpy as np
import os
import sys
import argparse

def analyze_onnx_model(model_path):
    """ONNXãƒ¢ãƒ‡ãƒ«ã®è©³ç´°æƒ…å ±ã‚’åˆ†æ"""
    print(f"=== Analyzing ONNX model: {model_path} ===")
    
    if not os.path.exists(model_path):
        print(f"ERROR: Model file not found: {model_path}")
        return False
    
    try:
        # ONNXãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
        model = onnx.load(model_path)
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
        print(f"Producer: {model.producer_name}")
        print(f"Version: {model.producer_version}")
        print(f"Model Version: {model.model_version}")
        print(f"Doc String: {model.doc_string}")
        print()
        
        # å…¥åŠ›æƒ…å ±ã‚’è¡¨ç¤º
        print("=== INPUT INFORMATION ===")
        for i, input_tensor in enumerate(model.graph.input):
            print(f"Input {i}:")
            print(f"  Name: {input_tensor.name}")
            print(f"  Type: {input_tensor.type}")
            
            # å½¢çŠ¶æƒ…å ±ã‚’å–å¾—
            if input_tensor.type.tensor_type.shape.dim:
                shape = []
                for dim in input_tensor.type.tensor_type.shape.dim:
                    if dim.dim_value:
                        shape.append(dim.dim_value)
                    elif dim.dim_param:
                        shape.append(dim.dim_param)
                    else:
                        shape.append("unknown")
                print(f"  Shape: {shape}")
            print()
        
        # å‡ºåŠ›æƒ…å ±ã‚’è¡¨ç¤º
        print("=== OUTPUT INFORMATION ===")
        for i, output_tensor in enumerate(model.graph.output):
            print(f"Output {i}:")
            print(f"  Name: {output_tensor.name}")
            print(f"  Type: {output_tensor.type}")
            
            # å½¢çŠ¶æƒ…å ±ã‚’å–å¾—
            if output_tensor.type.tensor_type.shape.dim:
                shape = []
                for dim in output_tensor.type.tensor_type.shape.dim:
                    if dim.dim_value:
                        shape.append(dim.dim_value)
                    elif dim.dim_param:
                        shape.append(dim.dim_param)
                    else:
                        shape.append("unknown")
                print(f"  Shape: {shape}")
            print()
        
        # ONNX Runtimeã§ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
        print("=== ONNX RUNTIME SESSION INFO ===")
        session = ort.InferenceSession(model_path)
        
        # å…¥åŠ›æƒ…å ±
        print("Runtime Input Info:")
        for input_meta in session.get_inputs():
            print(f"  Name: {input_meta.name}")
            print(f"  Shape: {input_meta.shape}")
            print(f"  Type: {input_meta.type}")
            print()
        
        # å‡ºåŠ›æƒ…å ±
        print("Runtime Output Info:")
        for output_meta in session.get_outputs():
            print(f"  Name: {output_meta.name}")
            print(f"  Shape: {output_meta.shape}")
            print(f"  Type: {output_meta.type}")
            print()
        
        # ãƒ†ã‚¹ãƒˆæ¨è«–ã®å®Ÿè¡Œ
        print("=== TEST INFERENCE ===")
        input_name = session.get_inputs()[0].name
        input_shape = session.get_inputs()[0].shape
        
        # å‹•çš„æ¬¡å…ƒã‚’1ã«ç½®ãæ›ãˆ
        test_shape = []
        for dim in input_shape:
            if isinstance(dim, str) or dim == -1:
                test_shape.append(1)
            else:
                test_shape.append(dim)
        
        print(f"Test input shape: {test_shape}")
        
        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§æ¨è«–å®Ÿè¡Œ
        dummy_input = np.random.rand(*test_shape).astype(np.float32)
        result = session.run(None, {input_name: dummy_input})
        
        print(f"Output shape: {result[0].shape}")
        print(f"Output dtype: {result[0].dtype}")
        print(f"Output range: [{result[0].min():.6f}, {result[0].max():.6f}]")
        print(f"Output mean: {result[0].mean():.6f}")
        print(f"Output std: {result[0].std():.6f}")
        
        # å½¢çŠ¶ã‹ã‚‰ãƒ†ãƒ³ã‚½ãƒ«å½¢å¼ã‚’æ¨å®š
        if len(test_shape) == 4:
            if test_shape[1] == 3:
                print("Tensor format: NCHW (batch, channels, height, width)")
            elif test_shape[3] == 3:
                print("Tensor format: NHWC (batch, height, width, channels)")
            else:
                print("Tensor format: Unknown")
        
        # æ­£è¦åŒ–ã®æ¨å®š
        print("\n=== NORMALIZATION ESTIMATION ===")
        if len(test_shape) == 4:
            # ç•°ãªã‚‹æ­£è¦åŒ–ã§æ¨è«–ãƒ†ã‚¹ãƒˆ
            normalized_inputs = {
                "0-1 normalization": np.random.rand(*test_shape).astype(np.float32),
                "[-1,1] normalization": (np.random.rand(*test_shape).astype(np.float32) - 0.5) * 2,
                "ImageNet normalization": (np.random.rand(*test_shape).astype(np.float32) - 0.485) / 0.229
            }
            
            for norm_name, norm_input in normalized_inputs.items():
                try:
                    norm_result = session.run(None, {input_name: norm_input})
                    print(f"{norm_name}: Output range [{norm_result[0].min():.6f}, {norm_result[0].max():.6f}], std: {norm_result[0].std():.6f}")
                except Exception as e:
                    print(f"{norm_name}: Failed - {e}")
        
        return True
        
    except Exception as e:
        print(f"ERROR: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description='ONNX Model Analyzer')
    parser.add_argument('model_paths', nargs='+', help='Path(s) to ONNX model file(s)')
    parser.add_argument('--compare', '-c', action='store_true', help='Compare multiple models')
    
    args = parser.parse_args()
    
    if len(args.model_paths) == 1:
        # å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®åˆ†æ
        analyze_onnx_model(args.model_paths[0])
    else:
        # è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒåˆ†æ
        for i, model_path in enumerate(args.model_paths):
            print(f"ğŸ” Analyzing model {i+1}/{len(args.model_paths)}: {os.path.basename(model_path)}")
            if analyze_onnx_model(model_path):
                print("âœ… Analysis completed successfully\n")
            else:
                print("âŒ Analysis failed\n")
            
            if i < len(args.model_paths) - 1:
                print("=" * 80)
                print()

if __name__ == "__main__":
    main()